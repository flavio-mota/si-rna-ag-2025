{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f3b596b",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavio-mota/si-rna-ag-2025/blob/main/Aula%202%20-%20MLP/Implementando_MLP_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e388a1",
      "metadata": {
        "id": "71e388a1"
      },
      "source": [
        "\n",
        "# Implementando um MLP com TensorFlow\n",
        "\n",
        "## Introdução ao TensorFlow e ao MLP\n",
        "\n",
        "O TensorFlow é uma das bibliotecas mais populares para construir e treinar redes neurais.\n",
        "Ela fornece uma interface de alto nível chamada **Keras**, que facilita a criação de modelos como o MLP (Multilayer Perceptron).\n",
        "\n",
        "Um MLP é uma rede formada por múltiplas camadas de neurônios artificiais — uma camada de entrada,\n",
        "camadas ocultas e uma camada de saída.\n",
        "Cada camada é totalmente conectada à próxima, e os pesos são ajustados durante o treinamento\n",
        "por meio do algoritmo de retropropagação e do gradiente descendente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b495b3b8",
      "metadata": {
        "id": "b495b3b8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8073d75f",
      "metadata": {
        "id": "8073d75f"
      },
      "source": [
        "## O conjunto de dados MNIST\n",
        "\n",
        "O **MNIST** é um dos conjuntos de dados mais clássicos no estudo de redes neurais.  \n",
        "Ele contém **70.000 imagens de dígitos manuscritos** (de 0 a 9), sendo **60.000 para treino** e **10.000 para teste**.\n",
        "\n",
        "Cada imagem tem:\n",
        "- **28 × 28 pixels**, totalizando **784 pontos**;\n",
        "- Tons de cinza variando de 0 (preto) a 255 (branco);\n",
        "- Um **rótulo (label)** indicando qual número a imagem representa.\n",
        "\n",
        "---\n",
        "\n",
        "### Por que esse conjunto é importante?\n",
        "\n",
        "O MNIST é um ótimo ponto de partida porque:\n",
        "- É pequeno e fácil de processar;\n",
        "- Permite treinar rapidamente modelos simples como o **MLP**;\n",
        "- Mostra de forma intuitiva como a rede aprende a reconhecer **padrões visuais**.\n",
        "\n",
        "---\n",
        "\n",
        "### Pré-processamento dos dados\n",
        "\n",
        "As redes neurais trabalham melhor com valores **normalizados** (em faixas pequenas, como de 0 a 1).  \n",
        "Por isso, dividimos todos os pixels por 255, para que fiquem dentro dessa escala.\n",
        "\n",
        "Além disso, o **MLP espera vetores como entrada**, e não matrizes bidimensionais.  \n",
        "Como cada imagem tem 28×28 pixels, precisamos **“achatar” (flatten)** a matriz em um vetor de 784 posições:\n",
        "\n",
        "```python\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "```\n",
        "\n",
        "Esse processo **não altera as informações da imagem**, apenas muda sua forma para que cada pixel seja tratado como uma **característica (feature)** de entrada.\n",
        "\n",
        "---\n",
        "\n",
        "### Formato final dos dados\n",
        "\n",
        "Após o achatamento:\n",
        "- Cada imagem é representada por **784 números** (intensidades dos pixels);\n",
        "- Cada número indica “o quanto de luz” há naquela posição da imagem;\n",
        "- Assim, o modelo pode usar esses valores como variáveis de entrada para aprender os padrões que caracterizam cada dígito.\n",
        "\n",
        "Esse formato é ideal para redes como o **Perceptron Multicamadas (MLP)**, que operam sobre vetores de atributos em vez de estruturas bidimensionais como imagens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b0cb06",
      "metadata": {
        "id": "e5b0cb06"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalização\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Flatten\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "\n",
        "print(\"Formato dos dados de treino:\", x_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EGIynwivlkLy",
      "metadata": {
        "id": "EGIynwivlkLy"
      },
      "source": [
        "## Visualizando uma imagem do MNIST e o processo de achatamento\n",
        "\n",
        "Antes de passarmos para o modelo, vamos **visualizar uma imagem real do MNIST** e entender o que significa \"achatar\" a matriz 28×28 em um vetor de 784 valores.\n",
        "\n",
        "Cada imagem no MNIST é uma **matriz bidimensional**, onde cada posição representa a **intensidade do pixel** (entre 0 e 255).\n",
        "\n",
        "Ao achatar a imagem, transformamos essa matriz em uma **sequência linear de números**, para que o MLP consiga processar cada pixel como uma *entrada independente*.\n",
        "\n",
        "O código abaixo mostra esse processo visualmente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5o8T-jMnllxO",
      "metadata": {
        "id": "5o8T-jMnllxO"
      },
      "outputs": [],
      "source": [
        "# Carregando o conjunto de dados MNIST\n",
        "(x_tr_plot, y_tr_plot), (x_ts_plot, y_ts_plot) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Seleciona uma imagem qualquer do conjunto de treino\n",
        "idx = 0\n",
        "imagem = x_tr_plot[idx]\n",
        "rotulo = y_tr_plot[idx]\n",
        "# Achata a imagem (flatten)\n",
        "vetor = imagem.flatten()\n",
        "\n",
        "# Figura 1: imagem original 28x28\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagem, cmap='gray')\n",
        "plt.title(f\"Imagem original (28×28)\\nRótulo: {rotulo}\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Parte 2: imagem achatada (vetor visual)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(vetor[np.newaxis, :], cmap='gray', aspect='auto')\n",
        "plt.title(\"Imagem achatada (vetor 1×784)\")\n",
        "plt.yticks([])\n",
        "plt.xlabel(\"Posição no vetor\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Exibe os primeiros valores do vetor achatado\n",
        "print(\"Primeiros 20 valores do vetor achatado:\")\n",
        "print(vetor[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NUqjSt46mnk_",
      "metadata": {
        "id": "NUqjSt46mnk_"
      },
      "source": [
        "### O que esse código mostra\n",
        "\n",
        "1. **Imagem original (28×28):** matriz bidimensional com as intensidades dos pixels.  \n",
        "2. **Imagem achatada (1×784):** a mesma imagem transformada em um vetor unidimensional, que é o formato de entrada esperado pelo MLP.  \n",
        "3. Cada **quadradinho** no vetor corresponde exatamente a um **pixel** da imagem original, apenas reorganizado em sequência.  \n",
        "\n",
        "O achatamento não altera as informações — ele apenas muda o formato para que a rede possa processar os dados como uma lista de valores de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fedf5c8",
      "metadata": {
        "id": "8fedf5c8"
      },
      "source": [
        "## Construindo o modelo MLP\n",
        "\n",
        "Agora que os dados estão prontos, vamos criar o nosso modelo de rede neural.  \n",
        "Usaremos a **API `Sequential`** do Keras, que é a forma mais simples de empilhar camadas em sequência — da entrada até a saída.\n",
        "\n",
        "A ideia é que os dados entrem pela primeira camada (entrada), passem por uma ou mais camadas ocultas e cheguem à camada de saída, onde será feita a previsão final.\n",
        "\n",
        "---\n",
        "\n",
        "### Passo a passo da construção\n",
        "\n",
        "```python\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(784,)),            # 28x28 = 784 pixels (camada de entrada)\n",
        "    layers.Dense(128, activation='relu'),  # Primeira camada oculta\n",
        "    layers.Dense(64, activation='relu'),   # Segunda camada oculta\n",
        "    layers.Dense(10, activation='softmax') # Camada de saída (10 dígitos)\n",
        "])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32418312",
      "metadata": {
        "id": "32418312"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gclla0bSjIVI",
      "metadata": {
        "id": "gclla0bSjIVI"
      },
      "source": [
        "### Explicando cada parte\n",
        "\n",
        "**`models.Sequential([...])`**  \n",
        "Cria um modelo onde as camadas são empilhadas de forma linear — a saída de uma camada é automaticamente a entrada da próxima.  \n",
        "Essa é a estrutura mais comum para redes *feedforward* como o MLP.\n",
        "\n",
        "**`layers.Input(shape=(784,))`**  \n",
        "Define o formato dos dados de entrada.  \n",
        "No MNIST, cada imagem é 28×28 pixels, e aqui ela foi achatada (*flattened*) em um vetor de 784 posições.\n",
        "\n",
        "**`layers.Dense(units, activation='relu')`**  \n",
        "Cria uma camada totalmente conectada (*fully connected*).  \n",
        "- `units` indica o número de neurônios (aqui usamos 128 e depois 64).  \n",
        "- `activation='relu'` aplica a função **ReLU (Rectified Linear Unit)**, que substitui valores negativos por zero e ajuda a rede a aprender relações não lineares.\n",
        "\n",
        "**`layers.Dense(10, activation='softmax')`**  \n",
        "Cria a camada de saída com **10 neurônios** (um para cada dígito, de 0 a 9).  \n",
        "A função *softmax* converte as saídas em probabilidades que somam 1, permitindo interpretar qual dígito o modelo acredita ser mais provável.\n",
        "\n",
        "---\n",
        "\n",
        "Por fim, podemos visualizar o resumo da arquitetura com:\n",
        "\n",
        "```python\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "Isso exibe a estrutura da rede e o número total de parâmetros treináveis em cada camada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8xCiwGY0jgpw",
      "metadata": {
        "id": "8xCiwGY0jgpw"
      },
      "source": [
        "## Compilando o modelo\n",
        "\n",
        "Antes de treinar a rede, precisamos **compilar** o modelo.  \n",
        "Isso significa dizer ao TensorFlow como ele deve aprender a partir dos dados.\n",
        "\n",
        "Durante a compilação, definimos três informações principais:\n",
        "\n",
        "1. **Como a rede aprende** – ou seja, qual o método será usado para ajustar os pesos (isso é controlado pelo otimizador).  \n",
        "2. **Como medir o erro** – uma função que indica o quanto as previsões da rede estão diferentes dos valores reais.  \n",
        "3. **Quais métricas acompanhar** – por exemplo, a acurácia, que mostra o percentual de acertos.\n",
        "\n",
        "Mesmo sem entrar em detalhes matemáticos agora, o importante é entender que essa etapa prepara o modelo para o aprendizado, dizendo *o que ele deve minimizar* (o erro) e *como acompanhar o desempenho*.\n",
        "\n",
        "```python\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "```\n",
        "\n",
        "O comando acima apenas define essas instruções.  \n",
        "O verdadeiro processo de aprendizado ocorrerá no momento do **treinamento**, quando o modelo ajustará os pesos a partir dos exemplos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc846c1",
      "metadata": {
        "id": "1cc846c1"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2158cf5f",
      "metadata": {
        "id": "2158cf5f"
      },
      "source": [
        "## Treinando o modelo\n",
        "\n",
        "Agora que o modelo foi compilado, podemos **treiná-lo**.  \n",
        "É nesse momento que a rede começa a aprender a reconhecer padrões nos dados.\n",
        "\n",
        "Durante o treinamento, o TensorFlow envia os exemplos de entrada (as imagens do conjunto de treino) para o modelo e compara as previsões feitas com os valores reais (os dígitos corretos).  \n",
        "Com base nessa diferença, ele ajusta os pesos internos da rede para reduzir o erro — esse processo é conhecido como **retropropagação** (*backpropagation*).\n",
        "\n",
        "---\n",
        "\n",
        "### O que acontece em cada etapa\n",
        "\n",
        "- **Época (epoch)**: representa **uma passagem completa por todos os dados de treino**.  \n",
        "  Normalmente treinamos o modelo por várias épocas, para que ele vá melhorando gradualmente a cada ciclo.\n",
        "\n",
        "- **Lote (batch)**: como o conjunto de dados pode ser muito grande, ele é dividido em pequenos grupos (lotes).  \n",
        "  A cada lote, o modelo faz previsões, calcula o erro e ajusta os pesos — isso acelera o processo de aprendizado e evita sobrecarga de memória.\n",
        "\n",
        "- **Retropropagação (backpropagation)**: é o algoritmo que permite à rede ajustar seus pesos a partir dos erros cometidos.  \n",
        "  Ele “propaga o erro para trás” na rede, atualizando os pesos de forma que a próxima previsão seja mais precisa.\n",
        "\n",
        "---\n",
        "\n",
        "### Treinando na prática\n",
        "\n",
        "```python\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "O comando acima:\n",
        "- Treina o modelo por **10 épocas**.\n",
        "- Usa os dados de treino (`x_train`, `y_train`) para ajustar os pesos.  \n",
        "- Usa os dados de teste (`x_test`, `y_test`) apenas para verificar como a rede está se saindo durante o processo (validação).  \n",
        "- Armazena o histórico do aprendizado na variável `history`, que depois pode ser usado para visualizar a evolução da acurácia e do erro.\n",
        "\n",
        "---\n",
        "\n",
        "Ao final, o modelo deverá ter aprendido a reconhecer os padrões visuais que representam cada dígito (0 a 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d232ef0",
      "metadata": {
        "id": "1d232ef0"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHECPda2kHh-",
      "metadata": {
        "id": "KHECPda2kHh-"
      },
      "source": [
        "## Visualizando o aprendizado\n",
        "\n",
        "Durante o treinamento, o modelo registra a evolução do seu desempenho em cada época.  \n",
        "Podemos visualizar esses resultados para entender **como o aprendizado evoluiu** e se o modelo está realmente melhorando.\n",
        "\n",
        "---\n",
        "\n",
        "### Gráfico de acurácia\n",
        "\n",
        "O gráfico abaixo mostra a **acurácia** (percentual de acertos) do modelo em duas situações:\n",
        "\n",
        "- **Acurácia de treino (`accuracy`)** → indica o desempenho do modelo sobre os dados usados para aprender.  \n",
        "- **Acurácia de validação (`val_accuracy`)** → mostra como o modelo se comporta com dados que ele **nunca viu antes**, servindo para verificar se o aprendizado está se generalizando bem.\n",
        "\n",
        "```python\n",
        "plt.plot(history.history['accuracy'], label='Acurácia (treino)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia (validação)')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.title('Evolução do aprendizado')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Como interpretar o gráfico\n",
        "\n",
        "- Se ambas as curvas (treino e validação) **sobem e se aproximam**, o modelo está aprendendo bem.  \n",
        "- Se a acurácia de treino continuar subindo, mas a de validação **parar de crescer ou cair**, o modelo pode estar **decorando os dados** (isso é chamado de *overfitting*).  \n",
        "- Se ambas as acurácias forem baixas, talvez a rede **precise de mais épocas** ou **camadas** para aprender padrões mais complexos.\n",
        "\n",
        "---\n",
        "\n",
        "Visualizar o aprendizado é uma forma prática de acompanhar o comportamento do modelo e identificar se ele está evoluindo de forma saudável.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5c24f9",
      "metadata": {
        "id": "6b5c24f9"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'], label='Acurácia (treino)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia (validação)')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.title('Evolução do aprendizado')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tlszQpQqkWas",
      "metadata": {
        "id": "tlszQpQqkWas"
      },
      "source": [
        "## Avaliando o modelo\n",
        "\n",
        "Depois que o treinamento termina, é hora de verificar **como o modelo se sai em dados totalmente novos**.  \n",
        "Essa etapa é chamada de **avaliação** e serve para medir a capacidade real da rede de generalizar o que aprendeu.\n",
        "\n",
        "Durante o treino, o modelo já viu exemplos dos dígitos várias vezes — então, ele pode ter “decorado” parte das relações.  \n",
        "A avaliação com o conjunto de **teste** garante que medimos o desempenho sobre imagens que o modelo **nunca viu antes**.\n",
        "\n",
        "---\n",
        "\n",
        "### Diferença entre treino, validação e teste\n",
        "\n",
        "- **Treino (training set)** → usado para ajustar os pesos da rede e ensinar o modelo.  \n",
        "- **Validação (validation set)** → usado durante o treinamento apenas para acompanhar o progresso, ajudando a identificar quando o modelo começa a superajustar.  \n",
        "- **Teste (test set)** → usado **apenas no final**, para avaliar o desempenho final do modelo em dados novos.\n",
        "\n",
        "---\n",
        "\n",
        "### Avaliando na prática\n",
        "\n",
        "```python\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Acurácia no conjunto de teste: {test_acc:.4f}\")\n",
        "```\n",
        "\n",
        "Esse comando executa o modelo em todas as imagens do conjunto de teste e calcula:\n",
        "\n",
        "- **Perda (loss)**: representa o erro médio das previsões.  \n",
        "- **Acurácia (accuracy)**: mostra o percentual de acertos do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretando o resultado\n",
        "\n",
        "Uma acurácia alta (acima de 0.90, por exemplo) indica que o modelo conseguiu **aprender bem os padrões** do conjunto de dados e está **generalizando adequadamente**.  \n",
        "Se a acurácia de teste for muito menor que a de treino, o modelo pode ter **superajustado** — ou seja, aprendido demais sobre os exemplos específicos de treino, perdendo a capacidade de generalizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47c993b",
      "metadata": {
        "id": "c47c993b"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Acurácia no conjunto de teste: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eIDl5xXFkogP",
      "metadata": {
        "id": "eIDl5xXFkogP"
      },
      "source": [
        "## Visualizando previsões\n",
        "\n",
        "Agora que o modelo foi treinado e avaliado, podemos **ver na prática** como ele realiza as classificações.  \n",
        "Cada imagem do conjunto de teste é enviada para a rede, que retorna **10 probabilidades** — uma para cada dígito (de 0 a 9).  \n",
        "O número com a maior probabilidade é considerado a **previsão final** do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Como funciona internamente\n",
        "\n",
        "- A última camada da rede usa a função **softmax**, que transforma as saídas em **probabilidades que somam 1**.  \n",
        "- Assim, o modelo não apenas diz “qual número ele acha que é”, mas também **o quanto ele tem confiança** nessa resposta.  \n",
        "- Por exemplo, uma previsão pode indicar:\n",
        "  ```\n",
        "  [0.01, 0.02, 0.88, 0.03, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
        "  ```\n",
        "  Nesse caso, o modelo prevê que a imagem representa o número **2**, com 88% de confiança.\n",
        "\n",
        "---\n",
        "\n",
        "### Visualizando as previsões\n",
        "\n",
        "O código abaixo mostra algumas imagens do conjunto de teste com suas previsões e valores reais:\n",
        "\n",
        "```python\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "def plot_prediction(i):\n",
        "    plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Previsto: {np.argmax(predictions[i])} | Real: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plot_prediction(i)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretando os resultados\n",
        "\n",
        "Ao observar as imagens:\n",
        "- Se o valor previsto for igual ao valor real, significa que o modelo **reconheceu corretamente o dígito**.  \n",
        "- Quando houver erro, é interessante analisar se o dígito era difícil até mesmo para um humano (por exemplo, 4 e 9 mal escritos).  \n",
        "- Essa etapa ajuda a perceber **onde o modelo ainda confunde padrões**, fornecendo pistas para possíveis melhorias (mais camadas, mais dados ou mais épocas).\n",
        "\n",
        "---\n",
        "\n",
        "Essa visualização torna o aprendizado mais concreto, permitindo “ver” o que a rede aprendeu e como ela toma decisões.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566630a",
      "metadata": {
        "id": "9566630a"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "def plot_prediction(i):\n",
        "    plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Previsto: {np.argmax(predictions[i])} | Real: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plot_prediction(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a862e7b5",
      "metadata": {
        "id": "a862e7b5"
      },
      "source": [
        "\n",
        "## Conclusão\n",
        "\n",
        "Nesta atividade, construímos um MLP usando TensorFlow e Keras, explorando:\n",
        "- A estrutura multicamada do Perceptron;\n",
        "- O processo de treinamento com retropropagação;\n",
        "- A importância das funções de ativação e do gradiente descendente;\n",
        "- A capacidade do modelo de aprender padrões complexos (no caso, reconhecer dígitos manuscritos).\n",
        "\n",
        "Esse mesmo raciocínio pode ser aplicado a outros problemas de classificação — basta adaptar os dados e o número de saídas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L6dSR1ydm8Y9",
      "metadata": {
        "id": "L6dSR1ydm8Y9"
      },
      "source": [
        "## Exercícios práticos\n",
        "\n",
        "Agora que você construiu e treinou um MLP para reconhecer dígitos do MNIST, é hora de **explorar o comportamento do modelo** e observar como as escolhas de arquitetura afetam o resultado.\n",
        "\n",
        "### 1️⃣ Variação de camadas e neurônios\n",
        "Crie novos modelos modificando:\n",
        "- O **número de camadas ocultas** (tente usar 1, 2 ou 3 camadas);\n",
        "- O **número de neurônios** em cada camada (por exemplo, 32, 64, 128, 256).\n",
        "\n",
        "Treine cada modelo e **compare a acurácia final** e o tempo de treinamento.\n",
        "\n",
        "> 💡 *Dica:* redes maiores tendem a aprender mais, mas também podem demorar mais e correr o risco de “decorar” os dados (overfitting).\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ Funções de ativação\n",
        "Troque a função de ativação `relu` por outras, como:\n",
        "```python\n",
        "activation='sigmoid'\n",
        "```\n",
        "ou\n",
        "```python\n",
        "activation='tanh'\n",
        "```\n",
        "\n",
        "Observe como isso influencia:\n",
        "- A **velocidade de aprendizado** (as curvas sobem mais devagar ou mais rápido?);\n",
        "- A **acurácia final** do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ Número de épocas\n",
        "Mude o número de épocas no treinamento:\n",
        "```python\n",
        "model.fit(x_train, y_train, epochs=5, ...)\n",
        "```\n",
        "ou\n",
        "```python\n",
        "model.fit(x_train, y_train, epochs=20, ...)\n",
        "```\n",
        "\n",
        "Compare as curvas de treino e validação para identificar quando o modelo **começa a parar de melhorar** ou **superajusta**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ Avaliação visual\n",
        "Escolha algumas imagens em que o modelo errou e tente entender **por que** ele se confundiu.  \n",
        "Você pode usar o código abaixo como ponto de partida:\n",
        "\n",
        "```python\n",
        "for i in range(100):\n",
        "    pred = np.argmax(predictions[i])\n",
        "    real = y_test[i]\n",
        "    if pred != real:\n",
        "        plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "        plt.title(f\"Previsto: {pred} | Real: {real}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        break\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gJRhmYP3nGG_",
      "metadata": {
        "id": "gJRhmYP3nGG_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
