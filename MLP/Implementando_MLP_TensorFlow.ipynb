{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f3b596b",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavio-mota/si-rna-ag-2025/blob/main/Aula%202%20-%20MLP/Implementando_MLP_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e388a1",
      "metadata": {
        "id": "71e388a1"
      },
      "source": [
        "\n",
        "# Implementando um MLP com TensorFlow\n",
        "\n",
        "## Introdu√ß√£o ao TensorFlow e ao MLP\n",
        "\n",
        "O TensorFlow √© uma das bibliotecas mais populares para construir e treinar redes neurais.\n",
        "Ela fornece uma interface de alto n√≠vel chamada **Keras**, que facilita a cria√ß√£o de modelos como o MLP (Multilayer Perceptron).\n",
        "\n",
        "Um MLP √© uma rede formada por m√∫ltiplas camadas de neur√¥nios artificiais ‚Äî uma camada de entrada,\n",
        "camadas ocultas e uma camada de sa√≠da.\n",
        "Cada camada √© totalmente conectada √† pr√≥xima, e os pesos s√£o ajustados durante o treinamento\n",
        "por meio do algoritmo de retropropaga√ß√£o e do gradiente descendente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b495b3b8",
      "metadata": {
        "id": "b495b3b8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8073d75f",
      "metadata": {
        "id": "8073d75f"
      },
      "source": [
        "## O conjunto de dados MNIST\n",
        "\n",
        "O **MNIST** √© um dos conjuntos de dados mais cl√°ssicos no estudo de redes neurais.  \n",
        "Ele cont√©m **70.000 imagens de d√≠gitos manuscritos** (de 0 a 9), sendo **60.000 para treino** e **10.000 para teste**.\n",
        "\n",
        "Cada imagem tem:\n",
        "- **28 √ó 28 pixels**, totalizando **784 pontos**;\n",
        "- Tons de cinza variando de 0 (preto) a 255 (branco);\n",
        "- Um **r√≥tulo (label)** indicando qual n√∫mero a imagem representa.\n",
        "\n",
        "---\n",
        "\n",
        "### Por que esse conjunto √© importante?\n",
        "\n",
        "O MNIST √© um √≥timo ponto de partida porque:\n",
        "- √â pequeno e f√°cil de processar;\n",
        "- Permite treinar rapidamente modelos simples como o **MLP**;\n",
        "- Mostra de forma intuitiva como a rede aprende a reconhecer **padr√µes visuais**.\n",
        "\n",
        "---\n",
        "\n",
        "### Pr√©-processamento dos dados\n",
        "\n",
        "As redes neurais trabalham melhor com valores **normalizados** (em faixas pequenas, como de 0 a 1).  \n",
        "Por isso, dividimos todos os pixels por 255, para que fiquem dentro dessa escala.\n",
        "\n",
        "Al√©m disso, o **MLP espera vetores como entrada**, e n√£o matrizes bidimensionais.  \n",
        "Como cada imagem tem 28√ó28 pixels, precisamos **‚Äúachatar‚Äù (flatten)** a matriz em um vetor de 784 posi√ß√µes:\n",
        "\n",
        "```python\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "```\n",
        "\n",
        "Esse processo **n√£o altera as informa√ß√µes da imagem**, apenas muda sua forma para que cada pixel seja tratado como uma **caracter√≠stica (feature)** de entrada.\n",
        "\n",
        "---\n",
        "\n",
        "### Formato final dos dados\n",
        "\n",
        "Ap√≥s o achatamento:\n",
        "- Cada imagem √© representada por **784 n√∫meros** (intensidades dos pixels);\n",
        "- Cada n√∫mero indica ‚Äúo quanto de luz‚Äù h√° naquela posi√ß√£o da imagem;\n",
        "- Assim, o modelo pode usar esses valores como vari√°veis de entrada para aprender os padr√µes que caracterizam cada d√≠gito.\n",
        "\n",
        "Esse formato √© ideal para redes como o **Perceptron Multicamadas (MLP)**, que operam sobre vetores de atributos em vez de estruturas bidimensionais como imagens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b0cb06",
      "metadata": {
        "id": "e5b0cb06"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normaliza√ß√£o\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Flatten\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "\n",
        "print(\"Formato dos dados de treino:\", x_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EGIynwivlkLy",
      "metadata": {
        "id": "EGIynwivlkLy"
      },
      "source": [
        "## Visualizando uma imagem do MNIST e o processo de achatamento\n",
        "\n",
        "Antes de passarmos para o modelo, vamos **visualizar uma imagem real do MNIST** e entender o que significa \"achatar\" a matriz 28√ó28 em um vetor de 784 valores.\n",
        "\n",
        "Cada imagem no MNIST √© uma **matriz bidimensional**, onde cada posi√ß√£o representa a **intensidade do pixel** (entre 0 e 255).\n",
        "\n",
        "Ao achatar a imagem, transformamos essa matriz em uma **sequ√™ncia linear de n√∫meros**, para que o MLP consiga processar cada pixel como uma *entrada independente*.\n",
        "\n",
        "O c√≥digo abaixo mostra esse processo visualmente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5o8T-jMnllxO",
      "metadata": {
        "id": "5o8T-jMnllxO"
      },
      "outputs": [],
      "source": [
        "# Carregando o conjunto de dados MNIST\n",
        "(x_tr_plot, y_tr_plot), (x_ts_plot, y_ts_plot) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Seleciona uma imagem qualquer do conjunto de treino\n",
        "idx = 0\n",
        "imagem = x_tr_plot[idx]\n",
        "rotulo = y_tr_plot[idx]\n",
        "# Achata a imagem (flatten)\n",
        "vetor = imagem.flatten()\n",
        "\n",
        "# Figura 1: imagem original 28x28\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagem, cmap='gray')\n",
        "plt.title(f\"Imagem original (28√ó28)\\nR√≥tulo: {rotulo}\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Parte 2: imagem achatada (vetor visual)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(vetor[np.newaxis, :], cmap='gray', aspect='auto')\n",
        "plt.title(\"Imagem achatada (vetor 1√ó784)\")\n",
        "plt.yticks([])\n",
        "plt.xlabel(\"Posi√ß√£o no vetor\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Exibe os primeiros valores do vetor achatado\n",
        "print(\"Primeiros 20 valores do vetor achatado:\")\n",
        "print(vetor[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NUqjSt46mnk_",
      "metadata": {
        "id": "NUqjSt46mnk_"
      },
      "source": [
        "### O que esse c√≥digo mostra\n",
        "\n",
        "1. **Imagem original (28√ó28):** matriz bidimensional com as intensidades dos pixels.  \n",
        "2. **Imagem achatada (1√ó784):** a mesma imagem transformada em um vetor unidimensional, que √© o formato de entrada esperado pelo MLP.  \n",
        "3. Cada **quadradinho** no vetor corresponde exatamente a um **pixel** da imagem original, apenas reorganizado em sequ√™ncia.  \n",
        "\n",
        "O achatamento n√£o altera as informa√ß√µes ‚Äî ele apenas muda o formato para que a rede possa processar os dados como uma lista de valores de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fedf5c8",
      "metadata": {
        "id": "8fedf5c8"
      },
      "source": [
        "## Construindo o modelo MLP\n",
        "\n",
        "Agora que os dados est√£o prontos, vamos criar o nosso modelo de rede neural.  \n",
        "Usaremos a **API `Sequential`** do Keras, que √© a forma mais simples de empilhar camadas em sequ√™ncia ‚Äî da entrada at√© a sa√≠da.\n",
        "\n",
        "A ideia √© que os dados entrem pela primeira camada (entrada), passem por uma ou mais camadas ocultas e cheguem √† camada de sa√≠da, onde ser√° feita a previs√£o final.\n",
        "\n",
        "---\n",
        "\n",
        "### Passo a passo da constru√ß√£o\n",
        "\n",
        "```python\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(784,)),            # 28x28 = 784 pixels (camada de entrada)\n",
        "    layers.Dense(128, activation='relu'),  # Primeira camada oculta\n",
        "    layers.Dense(64, activation='relu'),   # Segunda camada oculta\n",
        "    layers.Dense(10, activation='softmax') # Camada de sa√≠da (10 d√≠gitos)\n",
        "])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32418312",
      "metadata": {
        "id": "32418312"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gclla0bSjIVI",
      "metadata": {
        "id": "gclla0bSjIVI"
      },
      "source": [
        "### Explicando cada parte\n",
        "\n",
        "**`models.Sequential([...])`**  \n",
        "Cria um modelo onde as camadas s√£o empilhadas de forma linear ‚Äî a sa√≠da de uma camada √© automaticamente a entrada da pr√≥xima.  \n",
        "Essa √© a estrutura mais comum para redes *feedforward* como o MLP.\n",
        "\n",
        "**`layers.Input(shape=(784,))`**  \n",
        "Define o formato dos dados de entrada.  \n",
        "No MNIST, cada imagem √© 28√ó28 pixels, e aqui ela foi achatada (*flattened*) em um vetor de 784 posi√ß√µes.\n",
        "\n",
        "**`layers.Dense(units, activation='relu')`**  \n",
        "Cria uma camada totalmente conectada (*fully connected*).  \n",
        "- `units` indica o n√∫mero de neur√¥nios (aqui usamos 128 e depois 64).  \n",
        "- `activation='relu'` aplica a fun√ß√£o **ReLU (Rectified Linear Unit)**, que substitui valores negativos por zero e ajuda a rede a aprender rela√ß√µes n√£o lineares.\n",
        "\n",
        "**`layers.Dense(10, activation='softmax')`**  \n",
        "Cria a camada de sa√≠da com **10 neur√¥nios** (um para cada d√≠gito, de 0 a 9).  \n",
        "A fun√ß√£o *softmax* converte as sa√≠das em probabilidades que somam 1, permitindo interpretar qual d√≠gito o modelo acredita ser mais prov√°vel.\n",
        "\n",
        "---\n",
        "\n",
        "Por fim, podemos visualizar o resumo da arquitetura com:\n",
        "\n",
        "```python\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "Isso exibe a estrutura da rede e o n√∫mero total de par√¢metros trein√°veis em cada camada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8xCiwGY0jgpw",
      "metadata": {
        "id": "8xCiwGY0jgpw"
      },
      "source": [
        "## Compilando o modelo\n",
        "\n",
        "Antes de treinar a rede, precisamos **compilar** o modelo.  \n",
        "Isso significa dizer ao TensorFlow como ele deve aprender a partir dos dados.\n",
        "\n",
        "Durante a compila√ß√£o, definimos tr√™s informa√ß√µes principais:\n",
        "\n",
        "1. **Como a rede aprende** ‚Äì ou seja, qual o m√©todo ser√° usado para ajustar os pesos (isso √© controlado pelo otimizador).  \n",
        "2. **Como medir o erro** ‚Äì uma fun√ß√£o que indica o quanto as previs√µes da rede est√£o diferentes dos valores reais.  \n",
        "3. **Quais m√©tricas acompanhar** ‚Äì por exemplo, a acur√°cia, que mostra o percentual de acertos.\n",
        "\n",
        "Mesmo sem entrar em detalhes matem√°ticos agora, o importante √© entender que essa etapa prepara o modelo para o aprendizado, dizendo *o que ele deve minimizar* (o erro) e *como acompanhar o desempenho*.\n",
        "\n",
        "```python\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "```\n",
        "\n",
        "O comando acima apenas define essas instru√ß√µes.  \n",
        "O verdadeiro processo de aprendizado ocorrer√° no momento do **treinamento**, quando o modelo ajustar√° os pesos a partir dos exemplos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc846c1",
      "metadata": {
        "id": "1cc846c1"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2158cf5f",
      "metadata": {
        "id": "2158cf5f"
      },
      "source": [
        "## Treinando o modelo\n",
        "\n",
        "Agora que o modelo foi compilado, podemos **trein√°-lo**.  \n",
        "√â nesse momento que a rede come√ßa a aprender a reconhecer padr√µes nos dados.\n",
        "\n",
        "Durante o treinamento, o TensorFlow envia os exemplos de entrada (as imagens do conjunto de treino) para o modelo e compara as previs√µes feitas com os valores reais (os d√≠gitos corretos).  \n",
        "Com base nessa diferen√ßa, ele ajusta os pesos internos da rede para reduzir o erro ‚Äî esse processo √© conhecido como **retropropaga√ß√£o** (*backpropagation*).\n",
        "\n",
        "---\n",
        "\n",
        "### O que acontece em cada etapa\n",
        "\n",
        "- **√âpoca (epoch)**: representa **uma passagem completa por todos os dados de treino**.  \n",
        "  Normalmente treinamos o modelo por v√°rias √©pocas, para que ele v√° melhorando gradualmente a cada ciclo.\n",
        "\n",
        "- **Lote (batch)**: como o conjunto de dados pode ser muito grande, ele √© dividido em pequenos grupos (lotes).  \n",
        "  A cada lote, o modelo faz previs√µes, calcula o erro e ajusta os pesos ‚Äî isso acelera o processo de aprendizado e evita sobrecarga de mem√≥ria.\n",
        "\n",
        "- **Retropropaga√ß√£o (backpropagation)**: √© o algoritmo que permite √† rede ajustar seus pesos a partir dos erros cometidos.  \n",
        "  Ele ‚Äúpropaga o erro para tr√°s‚Äù na rede, atualizando os pesos de forma que a pr√≥xima previs√£o seja mais precisa.\n",
        "\n",
        "---\n",
        "\n",
        "### Treinando na pr√°tica\n",
        "\n",
        "```python\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "O comando acima:\n",
        "- Treina o modelo por **10 √©pocas**.\n",
        "- Usa os dados de treino (`x_train`, `y_train`) para ajustar os pesos.  \n",
        "- Usa os dados de teste (`x_test`, `y_test`) apenas para verificar como a rede est√° se saindo durante o processo (valida√ß√£o).  \n",
        "- Armazena o hist√≥rico do aprendizado na vari√°vel `history`, que depois pode ser usado para visualizar a evolu√ß√£o da acur√°cia e do erro.\n",
        "\n",
        "---\n",
        "\n",
        "Ao final, o modelo dever√° ter aprendido a reconhecer os padr√µes visuais que representam cada d√≠gito (0 a 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d232ef0",
      "metadata": {
        "id": "1d232ef0"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHECPda2kHh-",
      "metadata": {
        "id": "KHECPda2kHh-"
      },
      "source": [
        "## Visualizando o aprendizado\n",
        "\n",
        "Durante o treinamento, o modelo registra a evolu√ß√£o do seu desempenho em cada √©poca.  \n",
        "Podemos visualizar esses resultados para entender **como o aprendizado evoluiu** e se o modelo est√° realmente melhorando.\n",
        "\n",
        "---\n",
        "\n",
        "### Gr√°fico de acur√°cia\n",
        "\n",
        "O gr√°fico abaixo mostra a **acur√°cia** (percentual de acertos) do modelo em duas situa√ß√µes:\n",
        "\n",
        "- **Acur√°cia de treino (`accuracy`)** ‚Üí indica o desempenho do modelo sobre os dados usados para aprender.  \n",
        "- **Acur√°cia de valida√ß√£o (`val_accuracy`)** ‚Üí mostra como o modelo se comporta com dados que ele **nunca viu antes**, servindo para verificar se o aprendizado est√° se generalizando bem.\n",
        "\n",
        "```python\n",
        "plt.plot(history.history['accuracy'], label='Acur√°cia (treino)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acur√°cia (valida√ß√£o)')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.title('Evolu√ß√£o do aprendizado')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Como interpretar o gr√°fico\n",
        "\n",
        "- Se ambas as curvas (treino e valida√ß√£o) **sobem e se aproximam**, o modelo est√° aprendendo bem.  \n",
        "- Se a acur√°cia de treino continuar subindo, mas a de valida√ß√£o **parar de crescer ou cair**, o modelo pode estar **decorando os dados** (isso √© chamado de *overfitting*).  \n",
        "- Se ambas as acur√°cias forem baixas, talvez a rede **precise de mais √©pocas** ou **camadas** para aprender padr√µes mais complexos.\n",
        "\n",
        "---\n",
        "\n",
        "Visualizar o aprendizado √© uma forma pr√°tica de acompanhar o comportamento do modelo e identificar se ele est√° evoluindo de forma saud√°vel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5c24f9",
      "metadata": {
        "id": "6b5c24f9"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'], label='Acur√°cia (treino)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acur√°cia (valida√ß√£o)')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.title('Evolu√ß√£o do aprendizado')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tlszQpQqkWas",
      "metadata": {
        "id": "tlszQpQqkWas"
      },
      "source": [
        "## Avaliando o modelo\n",
        "\n",
        "Depois que o treinamento termina, √© hora de verificar **como o modelo se sai em dados totalmente novos**.  \n",
        "Essa etapa √© chamada de **avalia√ß√£o** e serve para medir a capacidade real da rede de generalizar o que aprendeu.\n",
        "\n",
        "Durante o treino, o modelo j√° viu exemplos dos d√≠gitos v√°rias vezes ‚Äî ent√£o, ele pode ter ‚Äúdecorado‚Äù parte das rela√ß√µes.  \n",
        "A avalia√ß√£o com o conjunto de **teste** garante que medimos o desempenho sobre imagens que o modelo **nunca viu antes**.\n",
        "\n",
        "---\n",
        "\n",
        "### Diferen√ßa entre treino, valida√ß√£o e teste\n",
        "\n",
        "- **Treino (training set)** ‚Üí usado para ajustar os pesos da rede e ensinar o modelo.  \n",
        "- **Valida√ß√£o (validation set)** ‚Üí usado durante o treinamento apenas para acompanhar o progresso, ajudando a identificar quando o modelo come√ßa a superajustar.  \n",
        "- **Teste (test set)** ‚Üí usado **apenas no final**, para avaliar o desempenho final do modelo em dados novos.\n",
        "\n",
        "---\n",
        "\n",
        "### Avaliando na pr√°tica\n",
        "\n",
        "```python\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_acc:.4f}\")\n",
        "```\n",
        "\n",
        "Esse comando executa o modelo em todas as imagens do conjunto de teste e calcula:\n",
        "\n",
        "- **Perda (loss)**: representa o erro m√©dio das previs√µes.  \n",
        "- **Acur√°cia (accuracy)**: mostra o percentual de acertos do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretando o resultado\n",
        "\n",
        "Uma acur√°cia alta (acima de 0.90, por exemplo) indica que o modelo conseguiu **aprender bem os padr√µes** do conjunto de dados e est√° **generalizando adequadamente**.  \n",
        "Se a acur√°cia de teste for muito menor que a de treino, o modelo pode ter **superajustado** ‚Äî ou seja, aprendido demais sobre os exemplos espec√≠ficos de treino, perdendo a capacidade de generalizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47c993b",
      "metadata": {
        "id": "c47c993b"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eIDl5xXFkogP",
      "metadata": {
        "id": "eIDl5xXFkogP"
      },
      "source": [
        "## Visualizando previs√µes\n",
        "\n",
        "Agora que o modelo foi treinado e avaliado, podemos **ver na pr√°tica** como ele realiza as classifica√ß√µes.  \n",
        "Cada imagem do conjunto de teste √© enviada para a rede, que retorna **10 probabilidades** ‚Äî uma para cada d√≠gito (de 0 a 9).  \n",
        "O n√∫mero com a maior probabilidade √© considerado a **previs√£o final** do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Como funciona internamente\n",
        "\n",
        "- A √∫ltima camada da rede usa a fun√ß√£o **softmax**, que transforma as sa√≠das em **probabilidades que somam 1**.  \n",
        "- Assim, o modelo n√£o apenas diz ‚Äúqual n√∫mero ele acha que √©‚Äù, mas tamb√©m **o quanto ele tem confian√ßa** nessa resposta.  \n",
        "- Por exemplo, uma previs√£o pode indicar:\n",
        "  ```\n",
        "  [0.01, 0.02, 0.88, 0.03, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
        "  ```\n",
        "  Nesse caso, o modelo prev√™ que a imagem representa o n√∫mero **2**, com 88% de confian√ßa.\n",
        "\n",
        "---\n",
        "\n",
        "### Visualizando as previs√µes\n",
        "\n",
        "O c√≥digo abaixo mostra algumas imagens do conjunto de teste com suas previs√µes e valores reais:\n",
        "\n",
        "```python\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "def plot_prediction(i):\n",
        "    plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Previsto: {np.argmax(predictions[i])} | Real: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plot_prediction(i)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretando os resultados\n",
        "\n",
        "Ao observar as imagens:\n",
        "- Se o valor previsto for igual ao valor real, significa que o modelo **reconheceu corretamente o d√≠gito**.  \n",
        "- Quando houver erro, √© interessante analisar se o d√≠gito era dif√≠cil at√© mesmo para um humano (por exemplo, 4 e 9 mal escritos).  \n",
        "- Essa etapa ajuda a perceber **onde o modelo ainda confunde padr√µes**, fornecendo pistas para poss√≠veis melhorias (mais camadas, mais dados ou mais √©pocas).\n",
        "\n",
        "---\n",
        "\n",
        "Essa visualiza√ß√£o torna o aprendizado mais concreto, permitindo ‚Äúver‚Äù o que a rede aprendeu e como ela toma decis√µes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566630a",
      "metadata": {
        "id": "9566630a"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "def plot_prediction(i):\n",
        "    plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Previsto: {np.argmax(predictions[i])} | Real: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plot_prediction(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a862e7b5",
      "metadata": {
        "id": "a862e7b5"
      },
      "source": [
        "\n",
        "## Conclus√£o\n",
        "\n",
        "Nesta atividade, constru√≠mos um MLP usando TensorFlow e Keras, explorando:\n",
        "- A estrutura multicamada do Perceptron;\n",
        "- O processo de treinamento com retropropaga√ß√£o;\n",
        "- A import√¢ncia das fun√ß√µes de ativa√ß√£o e do gradiente descendente;\n",
        "- A capacidade do modelo de aprender padr√µes complexos (no caso, reconhecer d√≠gitos manuscritos).\n",
        "\n",
        "Esse mesmo racioc√≠nio pode ser aplicado a outros problemas de classifica√ß√£o ‚Äî basta adaptar os dados e o n√∫mero de sa√≠das.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L6dSR1ydm8Y9",
      "metadata": {
        "id": "L6dSR1ydm8Y9"
      },
      "source": [
        "## Exerc√≠cios pr√°ticos\n",
        "\n",
        "Agora que voc√™ construiu e treinou um MLP para reconhecer d√≠gitos do MNIST, √© hora de **explorar o comportamento do modelo** e observar como as escolhas de arquitetura afetam o resultado.\n",
        "\n",
        "### 1Ô∏è‚É£ Varia√ß√£o de camadas e neur√¥nios\n",
        "Crie novos modelos modificando:\n",
        "- O **n√∫mero de camadas ocultas** (tente usar 1, 2 ou 3 camadas);\n",
        "- O **n√∫mero de neur√¥nios** em cada camada (por exemplo, 32, 64, 128, 256).\n",
        "\n",
        "Treine cada modelo e **compare a acur√°cia final** e o tempo de treinamento.\n",
        "\n",
        "> üí° *Dica:* redes maiores tendem a aprender mais, mas tamb√©m podem demorar mais e correr o risco de ‚Äúdecorar‚Äù os dados (overfitting).\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ Fun√ß√µes de ativa√ß√£o\n",
        "Troque a fun√ß√£o de ativa√ß√£o `relu` por outras, como:\n",
        "```python\n",
        "activation='sigmoid'\n",
        "```\n",
        "ou\n",
        "```python\n",
        "activation='tanh'\n",
        "```\n",
        "\n",
        "Observe como isso influencia:\n",
        "- A **velocidade de aprendizado** (as curvas sobem mais devagar ou mais r√°pido?);\n",
        "- A **acur√°cia final** do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### 3Ô∏è‚É£ N√∫mero de √©pocas\n",
        "Mude o n√∫mero de √©pocas no treinamento:\n",
        "```python\n",
        "model.fit(x_train, y_train, epochs=5, ...)\n",
        "```\n",
        "ou\n",
        "```python\n",
        "model.fit(x_train, y_train, epochs=20, ...)\n",
        "```\n",
        "\n",
        "Compare as curvas de treino e valida√ß√£o para identificar quando o modelo **come√ßa a parar de melhorar** ou **superajusta**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4Ô∏è‚É£ Avalia√ß√£o visual\n",
        "Escolha algumas imagens em que o modelo errou e tente entender **por que** ele se confundiu.  \n",
        "Voc√™ pode usar o c√≥digo abaixo como ponto de partida:\n",
        "\n",
        "```python\n",
        "for i in range(100):\n",
        "    pred = np.argmax(predictions[i])\n",
        "    real = y_test[i]\n",
        "    if pred != real:\n",
        "        plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "        plt.title(f\"Previsto: {pred} | Real: {real}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        break\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gJRhmYP3nGG_",
      "metadata": {
        "id": "gJRhmYP3nGG_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
